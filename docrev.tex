
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
\section{DM Documentation Review}\label{sec:docrev}

Here we gather every requirement or specification relevant to Special Programs in the existing DM documentation, identify areas where the intent of LSST DM is not adequately represented, and suggest clarifications, changes, or additions to these documents. If JIRA tickets have been spawned, they are noted by name. All remaining "Action Items" are associated with RFC-412, which is complete, and so should be disregarded. 

% % % % % % %
\subsection{Science Requirements Document, SRD, \citeds{LPM-17}}\label{ssec:docrev_srd}

This document does contain requirements for the data that are needed to achieve the main science goals, but the version available at this time is from 7/6/2011, and some specifications are out of date (e.g., the minimum exposure time is set to 5 seconds, in contrast with OSS-REQ-0291). The SRD makes two mentions of Special Programs: that the "LSST is well suited to conducting Deep Supernova Survey" (SRD, Section 2.3), and that 90\% of the observing time will be spent on the main survey, with the remaining 10\% used for a variety of other programs (SRD, Section 3.4). The latter we know to be an approximate estimate.

% % % % % % %
\subsection{LSST System Requirements, LSR, \citeds{LSE-29}}\label{ssec:docrev_lsr}

The LSR is derived from the SRD, and converts the high-level specifications from the SRD into system requirements, which flow-down to and in some cases repeated in the OSS and DMSR (next sections). We have the version of LSE-29 last revised on August 4, 2016.

\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{LSR-0} RFC (LSE-29): We propose to add a high-level requirement that DM reconfigure its pipelines and produce unique, separate data products for the accepted Special Programs, wherever possible, to better reflect its intent. This would flow-down to the DMSR. \end{enumerate}

$\bullet$ LSR-REQ-0102 defines the minimum interval between data releases to be \texttt{DRT1} = 1 year (1.4.2, Data Release Processing).
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{LSR-1} RFC (LSE-29): We propose to add a requirement on the schedule or latency for delivering Special Programs data products that is equivalent to the requirements for delivery of yearly data releases (LSR-REQ-0102). E.g., that data products from reconfigured pipelines will be made available on a intermediate time scale where the science goals require it. \end{enumerate}

$\bullet$ LSR-REQ-0111 requires that LSST be capable of obtaining \textit{and processing} exposures that were not taken in a standard visit mode, including those with minimum exposure time of \texttt{minExpTime} = 1 second, with the caveat that "non-standard visit exposures may possibly be degraded in some aspects of performance (e.g., cosmic ray rejection)" (2.3.1.2, Non-Standard Visit). The full capabilities of DM to process non-standard visits is not yet well defined; see \ref{NSV-1}.
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{LSR-2} RFC (LSE-29): We propose that LSR-REQ-0111, the requirement for DM to be capable of processing exposures that were not taken in a standard visit mode, might need to include a caveat once the DM capabilities for processing non-standard visits are truly defined (e.g., extremely short exposures). \end{enumerate}

$\bullet$ LSR-REQ-0032 requires that the LSST DM system provide three classes of science data products as "Level 1 (nightly cadence), Level 2 (data release cadence), and Level 3 (user-specified)", and subsequent sections describe the products and their timescales for delivery (2.4.5.1 Organization of Data Products).
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{LSR-3} RFC (LSE-29): We propose to add to LSR-REQ-0032, which requires that the DM system provide three classes science data products (nightly, yearly, and user-specified), the requirement to provide intermediate-cadence data products for Special Programs, whenever possible, to enable science. \end{enumerate}

$\bullet$ LSR-REQ-0041 requires that LSST support Level 3 data products "of a nature specified by users", and LSR-REQ-0106 that LSST provide software, services, and hardware resources to enable the production and storage of those products (2.4.5.1, Organization of Data Products).
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{LSR-4} RFC (LSE-29): We propose to add to LSR-REQ-0041, which requires that LSST provide software, services, and hardware resources to support Level 3 data products, the caveat that there will be technical limits on DM's ability to provide this in cases where an an intensive amount of additional computational resources is required. \end{enumerate}

$\bullet$ LSR-REQ-0042 requires that LSST produce the data products necessary to support the four primary science missions (dark energy, solar system, transients, milky way; 2.4.5.2, Science Flowdown). Since the science goals of the Special Programs flow down from these four primary science goals, no change is needed here.

$\bullet$ LSR-REQ-0055 requires that \texttt{userComputingFraction} = 10\% of the total LSST data processing capacity and storage space be allocated for user analysis and Level 3 pipelines and products (2.5.6, Community Computing Services). This is discussed further in Section \ref{ssec:docrev_sizing}.

$\bullet$ LSR-REQ-0075 defines that the WFD main survey science objectives will be met with 90\% of the observing time, with the remainder left to Special Programs (Section 3.3.1, Survey Time Allocation)


% % % % % % %
\subsection{Observatory System Specifications, OSS, \citeds{LSE-30}}\label{ssec:docrev_oss}

The OSS contains the requirements on the site, facility, and camera that are necessary to meet the requirements specified by the LSR (LSE-29) and the SRD (LPM-17). We have the version of LSE-30 last revised on February 10, 2017. Some of the aspects discussed in this section are not directly relevant to Data Management and are probably outside the scope of this study, but we keep them because they are relevant to Section \ref{ssec:data_bounds}.

$\bullet$ OSS-REQ-0027 requires that the scheduling system be able to optimize over at least \texttt{nSciProp} = 6 "science proposals", where these "proposals" are observing targets/constraints such as the distribution of filters, the astronomical conditions, and relative priority (OSS 2.1.1.2, Multiple Science Programs). {\bf JIRA ticket DM-12579 confirmed that there is no maximum number, and so many Special Programs will be able to be included in the scheduler}.

$\bullet$ OSS-REQ-0381 requires that the schedule be able to handle targets of opportunity, which would be relevant for e.g., Special Programs for gravitational wave follow-up (OSS 2.1.1.7, Visit Optimization).

$\bullet$ OSS-REQ-0189 and OSS-REQ-0190 set the minimum number of raw exposures to be supported as \texttt{nRawExpNightWinterAvg} = 1960 per night on average (but up to \texttt{nRawExpNightMax} = 2800 per night if e.g., two hours of a short-exposure twilight mini-survey are included) and \texttt{nRawExpYear} = 5.5$\times10^5$ per year, respectively. These numbers are set by predicting the maximum number of exposures that would be acquired on the longest night of the year in WFD cadence with 2 second slews, assuming $\sim80\%$ completion, but adding a 10\% margin. These estimates appear adequate for Special Programs in general.

$\bullet$ OSS-REQ-0194 and OSS-REQ-0323 set the minimum number of calibration exposures to be supported as \texttt{nCalibExpDay} = 450 on average and \texttt{nCalExpYear} = 1.5$\times10^5$ per year, respectively. These are \textit{minimums}, and so if a Special Program requires additional exposures, this should be possible to accommodate.

$\bullet$ Section 3.1.5 (OSS-REQ-0125 and those following) set the requirements for data products, including their variety and format (i.e., images and catalogs in Level 1 and 2), their precision (e.g., photometric and astrometric accuracy, completeness/spurious thresholds for DIA sources), and the timeline for the release of data products (Alerts, Level 1, and Level 2 ). Would these also apply to data from Special Programs? For example, OSS-REQ-0157 sets the fraction of false detections in deep CoAdds caused by unremoved artifacts to be \texttt{falseDeepDetect} = 0.1\%, but would this apply to a DDF stack?
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{OSS-3} RFC (LSE-30): We propose to add a statement to Section 3.1.5 of the OSS that DM will make a ``best effort" to meet the data products requirements with the Special Programs data. \end{enumerate}

$\bullet$ Section 3.5, Photometric Calibration, puts requirements on e.g., the relative contributions to photometric errors from instrumental (OSS-REQ-0282) and atmospheric (OSS-REQ-0276) transmissions, and requires that a catalog of $10000$ reference stars of $17<r<20$ mag per field be created for use (OSS-REQ-0285). The latter might not apply to Special Programs fields, but this probably isn't cause for concern.

$\bullet$ OSS-REQ-0319 sets the requirement that the LSST be capable of continuous operation throughout the night when all visits are separated only by the readout time, thereby enabling a deep drilling field style of observations (OSS 3.6.1.3, Continuous Exposures).

$\bullet$ OSS-REQ-0291 defines the minimum exposure time as $1$ second with a stretch goal of $0.1$ seconds, with a note that the spacing between exposures should be lengthened to $15$ seconds in order to maintain camera thermal stability, and that the thermal stability might also be affected with longer exposure times (OSS 3.6.1.4, Minimum Exposure Time). The implication for DM is that an exposure ingest rate will never exceed one per $15$ seconds.

$\bullet$ OSS-REQ-0293 requires that the maximum time for an operational filter change be $\texttt{tFilterChange} = 120$ seconds (unlikely to be much lower in practice), and OSS-REQ-0295 requires that the LSST support at least 4 changes per night (and 8 in the day). There is no officially required minimum time between filter changes. Unofficially, this is constrained by the total lifetime number of filter changes is $100,000$ over $15$ years, or an average of $18$ changes per night (see Section \ref{ssec:data_bounds}).

$\bullet$ OSS-REQ-0301 and OSS-REQ-0300 set the minimum time for continuous rotation tracking (\texttt{rotTrackTime} = 1 hour) and the half-range of the rotator motion (\texttt{rotTrackRange} = 90 minutes) respectively, but there do not seem to be any constraints on the speed of the rotator or the minimum distance between successive visits (3.6.3.2, Field de-rotation). Questions about whether there is a maximum rotation speed, or a limit on the amount of rotation per night (or in a 10-year lifetime), are raised in Section \ref{ssec:data_bounds}.

$\bullet$ OSS-REQ-0380 sets the rate and error limits for nonsidereal tracking, which presumably would only be relevant to a Special Program (3.6.3.7, Non-Sidereal Tracking).


% % % % % % %
\subsection{Data Management Subsystems Requirements, DMSR, \citeds{LSE-61}}\label{ssec:docrev_dmsr}

The DMSR contains the top-level requirements for all of Data Management, including processing pipelines and products (revision 2017-08-11).

\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{DMSR-0} RFC (LSE-61): We propose that the DMSR include a high-level specification (probably in Section 1.6) that the data from Special Programs will be included in the products of the wide-fast-deep main survey only when it is (a) possible and (b) beneficial to the primary science objectives of those products. It should also be updated to reflect the fact that DM will reconfigure its own pipelines ``wherever possible", process the Special Programs data, verify the unique data products, and make them publicly available. This would be a flow-down requirement from a similar new one added to the LSR (LSE-29).  \end{enumerate}

$\bullet$ DMS-REQ-0068 requires that each raw science image store metadata regarding the date, time, site, telescope, and camera -- missing from this might be the scheduler and program information. That kind of metadata will be necessary to identify images related to Special Programs (1.2.3, Raw Science Image Metadata). Related to this is DMS-REQ-0266, which requires the creation of an Exposure Catalog that also stores this kind of metadata independently, but also does not include scheduler and program information.
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{DMSR-1} RFC (LSE-61): We propose that DMS-REQ-0068 be updated to include that the scheduler and program metadata (i.e., a way to identify an image as being associated with a Special Program) with the raw science image, and/or with the Exposure Catalog (DMS-REQ-0068, -0266). We furthermore propose that the \texttt{visitID} and the total number of exposures in the visit are also included in this updated requirement (e.g., to accommodate a deep drilling sequence of a single visit of 50 exposures). \end{enumerate}

$\bullet$ DMS-REQ-0069 requires that DM produce processed visit images (overscan trimmed, ISR, snap-combined), and that they are not archived (but can be regenerated on demand). It also says that "this aspect of the processing for Special Programs data is specific to each program". It should be specified whether "this aspect" refers to the reduction or archiving of the processed visit images. If it refers to archiving, and if processed visit images for Special Programs can live on disk for longer, does this affect the sizing models? (1.2.2, Processed Visit Images). This question applies also to DMS-REQ-0010, which requires that DM create one difference image for each processed visit image (1.3.3, Difference Exposures). We assume this applies to standard visit images that \textit{can} be processed.
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{DMSR-2} RFC (LSE-61): We propose that DMS-REQ-0069 be clarified regarding whether processed single visits and/or difference images for Special Programs can stay archived and accessible to e.g., Level 3 pipelines, for a longer amount of time, possibly by user request. \end{enumerate}

$\bullet$ DMS-REQ-0274 sets the content of an Alert, and this does not currently include scheduler or program information. Adding this would enable users to e.g., use the LSST mini-broker to filter for only Alerts from their desired Special Program, in case they have a dedicated follow-up resource. Furthermore, it might facilitate follow-up more generally if users know e.g., that this Alert is from a field that is going to be observed again in $X$ minutes or $Y$ times in a night (1.3.13, Alert Content). However, the latter might be adequately available through the predicted visit schedule server specified by DMS-REQ-0353.
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{DMSR-4} RFC (LSE-61): We propose that DMS-REQ-0274, which sets the content of an Alert, be updated to include the program information and/or predicted revisit schedule (unless it is adequately available through the predicted visit schedule server specified by DMS-REQ-0353). \end{enumerate}

$\bullet$ DMS-REQ-0320 states that "it shall be possible for special programs to trigger their own data processing recipes". Assuming that this means that a header keyword identifying an image as related to a Special Program is sufficient to send it to a dedicated processing pipeline, it would appear that auto-triggering of alternative reduction pipelines is not currently supported by the DM system. This is handled by \ref{reconfig-2}. (1.6.1 Processing of Data From Special Programs).

$\bullet$ DMS-REQ-0321 and DMS-REQ-0344 together specify that the Level 1 processing for data Special Programs shall be completed with the same latencies as applied to data from the WFD main survey. It should be specified that this applies only to Special Programs data that consists of standard visit images (and not, e.g., very short or very long exposure times unless they can be shown to result in quality difference images), and that "reporting optical transients" within \texttt{OTT1} = 1 minute means contributing to the L1 Alert Stream. (1.6.2 Level 1 Processing of Special Programs Data, 1.6.3 Constraints on Level 1 Special Program Products Generation)
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{DMSR-6} RFC (LSE-61): We propose that DMS-REQ-0321 and -0344, which specify that the Level 1 processing for data Special Programs shall be completed with the same latencies as applied to data from the WFD main survey, be reworded to clarify that only Special Programs data that \textit{can} be incorporated into the Level 1 pipeline (i.e., standard visit images, or non-standard visit images that can be shown to result in quality DIA products), will be incorporated into Level 1 processing and contribute to the Alert Stream. \end{enumerate}

$\bullet$ DMS-REQ-0322 specifies that data products from Special Programs processing shall be stored in separate (but joinable) databases.

$\bullet$ DMS-REQ-0312 and -0313 require that DM maintain a live L1 and the two most recent DR L1 and L2 catalogs for access by users, but there is no corresponding access requirement for the data products of Special Programs (4.1, Data Archive).
\begin{enumerate}[resume,topsep=-10pt,after=\vspace{10pt},label= \textbf{Action \Roman*}] \item \label{DMSR-7} RFC (LSE-61): We propose that there be a requirement for maintenance of user access to data products of Special Programs with the same timescales as the WFD main survey data; i.e., similar to DMS-REQ-0312, -0313. \end{enumerate}


%$\bullet$ The following items are applicable to users processing data from Special Programs and/or reprocessing data from the WFD main survey. Since they're relevant to Special Programs, we mention them here, but they have not spawned any concerns. Section 2.9 "Level 3 Production" includes the requirements on access controls, external data, processing resource prioritization, consistency, provenance, and providing a software framework. Sections 3.1 "Software Architecture to Enable Community Re-Use" and 3.2 "Applications Software" describe aspects of the DM system that will be important to users, such as that the codes be extendable to both high-performance and desktop platforms, be able to handle simulated data and data from other instruments, and that a user interface will be provided. In Section 3.3 "Middleware Software", DMS-REQ-0298 requires that DM provide software to list and retrieve data, including raw data (3.3.2.2, Data Product and Raw Data Access), along with other user-access issues.



% % % % % % %
\subsection{Data Management Applications Design, DMAD, \citeds{LDM-151}}\label{ssec:docrev_dmad}

The DMAD specifies the design and implementation of the code and algorithms that will be used in the processing of images and creation of catalogs in the Level 1 AP, Level 2 DRP, and MOPS pipelines. We have used the version last revised 2017-07-19. As the DMAD focuses on the content of the code and algorithms, it is relatively agnostic as to whether the source of the data is the WFD main survey or Special Programs -- but does (in some places) explicitly assume standard visit images of $2\times15$ seconds as the raw image input. In fact, the phrase "Special Programs" appears four times: three times as a source of reference catalogs or training sets, and once as a potential source of visits that have only a single $15$ second snap. It is the DMAD's codes and algorithms that DM will be \textit{reconfiguring} to create pipelines for Special Programs -- any new algorithms that might enable science from Special Programs are considered beyond the scope of DM and will need to be developed as Level 3. This document will be handy to use in conjunction with Special Programs processing case studies (e.g., Section \ref{sec:SPCS}).

The purpose of this work on Special Programs is not to suggest any changes to the DMAD. Instead, here we list a couple of examples of algorithms that sit at the threshold between DM-produced and Level 3.

\subsubsection{Extreme-Depth CoAdds} The system has been sized to hold $\sim200$ exposures in memory at once, which defined by the current maximum number of visits per field in the WFD main survey in $10$ years (from a conversation with K.-T.~Lim). Note that the panchromatic CoAdds would be built from the individual filter CoAdds, so the algorithm does not need to handle $\sim800$ images. From a computational standpoint, $200$ is the maximum number of images that can be stacked with an algorithm that requires all images to be accessible in memory at once (i.e., loading all images and calculating the median for each pixel). Deeper stacks might be possible with algorithms that deal with images consequentially. It is conceivable that a Special Program which needs to stack $>200$ images is not possible to accomplish with reconfigured pipelines, and would have to be processed with external, user-contributed resources. However, the exact DM capabilities in this area are not yet well known because NCSA has not yet defined the machine capabilities. Furthermore, the planned commissioning data will go to a $\sim20$ year depth, and so it can reasonably be expected that DM will have to be able to accommodate at least a stack that deep.

\subsubsection{Deblending} The deep deblender algorithm described in Section 5.3.3 will, out of necessity, be optimized for use in the bulk of the WFD main survey. It may or may not end up being appropriate for use in the Galactic Plane mini-survey area, depending on the science goal. Level 3 deblenders for specific Special Programs fields may require development by the user community.

\subsubsection{Variability Characterization} The periodic and aperiodic variability characterizations described in Section 6.21 of the DMAD are placeholders, but are representative of what is likely to be implemented: algorithms that are applicable to a broad range of variability types. From DM's perspective, all that is needed is sufficient information to enable relatively useful filters, from which the downstream broker/user can do additional filtering, and these parameterizations might not be sufficient for all science goals. It is conceivable that the goals of a particular Special Program might require different algorithms; these could be provided by DM, or written as Level 3 and either made joinable to the DM reconfigured data products or perhaps incorporated directly.

\subsubsection{Photometric Redshifts} As described in Section 5.6.5 the Level 2 DRP \texttt{Object} catalog will include a photometric redshift, but this algorithm will be produced by the science community and then adopted and run at scale by DM. It is conceivable that the photo-$z$ algorithm for a Special Programs data set, such as a deep drilling field, might be different from that used for the WFD main survey.

% % % % % % %
\subsection{Data Products Definitions Document, DPDD, \citeds{LSE-163}}\label{ssec:docrev_dpdd}

The DPDD describes the data products -- the images and catalogs -- to be delivered from the Level 1 AP, Level 2 DRP, and MOPS pipelines. We have used the version last revised 2017-07-01. Section 6 describes the data products that DM will provide for Special Programs. It specifies that the processing will use the same software stack as the Level 1 and 2, will make separate imaging products and separate (but joinable) catalogs, and use $\lesssim10\%$ of the computational and storage facility of the total LSST processing cluster.

The LSST Database Schema Browser\footnote{\url{http://lsst-web.ncsa.illinois.edu/schema/index.php?sVer=baseline}} is another way to explore the contents of the planned DM catalogs. We identify a couple of potential changes that might be necessary to the schema, which are related to this study on Special Programs. These are not high priority.

$\bullet$ The database schema for \texttt{DIASource} does not appear to have an element that identifies which template image that was used. This will be needed for both Levels 1 and 3 differencing pipelines and products, for both Special Programs and WFD main survey data. DMS-REQ-0074 already does require that the identity of input exposures is stored for each difference image (LSE-61). In conversation with K.-T., we find that this isn't a problem, as it will be handled by provenance: the code configuration used and the time of processing are sufficient to identify and regenerate the template image. However, K.-T. has pointed out that the capability to regenerate the \textit{exact same} template -- the pixels that were subtracted -- is not a current deliverable. However, the stamp of the difference image will live on in the Alerts database, so we also do not foresee this as a problem.

$\bullet$ The DMAD specifies that externally defined targets can be incorporated into the \texttt{Objects} catalog (Section 3.2.5), and this may be a particular interest to Special Programs. It is unclear how such targets will be identified or flagged as such in the database schema, and whether we need to add an element for this. Currently, the \texttt{Object} database contains an element \texttt{prv\_inputId} which is an \texttt{integer}, and is described as the \textit{"Pointer to prv\_InputType. Indicates which input was used to produce a given object."} Is that all we need? {\bf JIRA ticket DM-12580 clarified that  \texttt{Object.prv\_inputID} in the database schema is one possible way to identify whether an \texttt{Object} is an externally provided coordinate}.

$\bullet$ The \texttt{Object} and \texttt{DIAObject} elements that have been reserved for variability characterization, as described in the DMAD and the DPDD, are as follows: \\
\texttt{Object} and \texttt{DIAObject.lcPeriodic} = \texttt{float[6 x 32]} = Periodic features extracted from light-curves using generalized Lomb-Scargle periodogram \\
\texttt{Object} and \texttt{DIAObject.lcNonPeriodic} = \texttt{float[6 x 32]} = Non-periodic features extracted from light-curves using generalized Lomb-Scargle periodogram \\
Section 6.21 of the DMAD describes the nominal algorithms to define these parameters, but as we mentioned in Section \ref{ssec:docrev_dmad}, different kinds of variability might be measurable Special Programs cadences that are quite different from the WFD main survey. Are 32 floats in each of the 6 filters always going to be a large enough volume? The Transients and Variable Stars Science Collaboration currently has a Task Force assigned to address this, and {\bf it is the topic of JIRA ticket DM-12581}.

% % % % % % %
\subsection{Photometric Calibration for the LSST Survey, \citeds{LSE-180}}

LSE-180 is built on \texttt{OpSim} runs that do include some nominal DDF, but the photometric calibration investigated in this work does not much deal with potential issues induced by non-standard visit patterns or exposure times of Special Programs, as its scope is the WFD main survey. Potential issues with DM processing -- including calibrations -- of non-standard visit exposure times is raised in Section \ref{ssec:dmplans_NSV}. Regarding the reduction and calibration of non-standard visit images, LSE-180 makes two relevant points: \\
$\bullet$ In LSE-180, it is assumed that all factors affecting the system transmission are stable on 15 second timescales (page 10), but not what the upper limit of that might be. \\
$\bullet$ LSE-180 comments on the dither pattern for the WFD survey in that "dither patterns where the overlap is one quarter of the field of view or more produce results meeting the SRD requirements", but this is specific to photometric calibration of the WFD. The LSE-180 also mentions that an inappropriate dither pattern can make it hard to correct for the variation of system bandpass as a function of the focal plane position -- but so long as this is solved in the WFD, the corrections can be applied to the much smaller amount of data from the Special Programs.

However, Lupton's recent work on calibrations has made much of LSE-180 obsolete, and it is not clear whether it is still needed as a separate document. At the time of writing, Lupton's most recent take on calibrations can be found in \url{https://github.com/lsst-dm/calibration/blob/master/calibration.pdf}. K.-T. referenced the Appendix B for the overview of calibration types, but it seems that there is not yet a final plan that can be assessed for its suitability for Special Programs. It is plausible that Special Programs could have their own calibration database, and obtaining additional calibration frames is not expected to cause a bottleneck (at the moment there is $\sim1.7$ hours per day for this, and exceeding this could eat into the engineering time). The most likely cause for trouble involving calibrations and Special Programs is the computational time needed to create the additional and/or different calibration files to be applied to non-standard Special Programs data, and/or the additional overhead required to load them in the Level 1 pipeline if the schedule interleaves SP-WFD-WFD-SP.

{\bf JIRA ticket DM-12582 is currently open, and aims to define the potential additional calibration needs of Special Programs data.}


% % % % % % %
\subsection{Computational Resources Sizing Documentation}\label{ssec:docrev_sizing}

In Section 6 of the DPDD, it is specified that the DM-provided processing of data from Special Programs will "use no more than $\lesssim10\%$ of computational and storage capacity of the LSST data processing cluster". This is based on the estimate that Special Programs data comprise $\sim10\%$ of the total observing time. Most Special Programs data will generate double the amount of processing and products: first, if and when they are incorporated into L1 and L2, and second, when their DM-provided reconfigured pipelines are run to generate independent and unique deep co-adds and catalogs. Based on this predicted multiple reprocessing, we might ask whether the "10\% of the computing resources" allocated for DM processing of Special Programs data is too small. This will depend on the exact final mix of Special Programs, which may well change from year to year, and furthermore the current error bars on the sizing are of order $\pm10\%$.

The Special Programs data also seems more likely than the WFD data to be processed a third time as part of science users Level 3 pipelines. LSST Science and Project Sizing Inputs spreadsheet (LSE-81) and explanation document (LSE-82) states that 10\% of the computing and storage resources estimated as necessary for the completion of the WFD Main Survey has been added to accommodate Level 3 data products. DM Compute Sizing spreadsheet (LDM-138) and explanation document (LDM-140) estimates the total compute resources needed for all processes, quoting the same 10\% addition for Level 3. DM Storage and I/O Sizing spreadsheet (LDM-141) and explanation document (LDM-139) estimates the total hardware needs, quoting the same 10\% addition for Level 3. As mentioned in Section \ref{ssec:docrev_lsr}, LSR-REQ-0055 requires that \texttt{userComputingFraction} = 10\% of the total LSST data processing capacity and storage space be allocated for user analysis and Level 3 pipelines and products. It is important to note that this 10\% is \textit{in addition to} the sizing of $90\%+10\%$ for WFD and Special Programs, and the reason why Level 3 is also sized at $+10\%$ is independent of the amount of observing time spent on Special Programs.

\begin{enumerate}[resume,topsep=-10pt,label= \textbf{Action \Roman*}] \item \label{Size-1} RFC (LSE-163): We propose to update the DPDD to better clarify that 10\% of the computational resources are allocated for processing Special Programs data because they are expected to use 10\% of the on-sky time, and that \textit{an additional 10\%} has been added to the overall computational system to accommodate user-driven processing to achieve specific science goals, which includes both reprocessing WFD main survey data and (re)processing Special Programs data. \end{enumerate}

Regarding the possibly computationally intensive (e.g., shift-and-stack) but scientifically necessary processing that will need to be done for Special Programs data as Level 3, it is unclear whether the location for this has been identified; Mario asks \textit{"whether this the same batch system we make available to the users for running Level 3 codes or the one that's used to process calibrations. Have these systems been sized?"}. The answer to this comes from K-T: \textit{In the current model, the same production batch system is used for processing calibrations (CPP), processing ``catch-up" L1, processing the L2 DRP, processing Special Programs as part of the L2 DRP, and processing large L3 jobs regardless of the type of data or processing. There is resource management and allocation applied, but there is flexibility and elasticity so that L3/DAC can ``borrow" from L2 DRP as long as the integrated usage over a long time period (months, quarter, or year) does not exceed policy."}

{\bf JIRA ticket DM-12583 is open to ensure that the overall DM computational system is appropriately sized}, given it is likely that a large portion of the 10\% of data from Special Programs might be multiply-processed: incorporated into the Level 1 pipeline, \textit{and} incorporated into the Level 2 data products, \textit{and} have their own dedicated reconfigured pipelines and separate products, \textit{and} have a higher probability for user-defined processing.

% % % % % % %
\subsection{The Limited Documentation Regarding Image Detection Efficiencies}

Characterizing the detection efficiencies will be just as important to Special Programs data as the Wide-Fast-Deep survey. Options such as planting fake sources may be both more manageable and more important to some Special Programs science goals. What, exactly, are the requirements on DM to provide detection efficiencies, and what are the current plans for providing this? Note that here we are talking about planting fakes in the single images for transient detection efficiencies with difference imaging analysis, and not planting fakes in the CoAdds for point-source limiting magnitudes).

$\bullet$ The DPDD (LSE-163) does not have any specific data product related to detection efficiencies, but Section 3.2 "Image Characterization Data" does specify that \textit{"Each processed image .. will record information on the pixel variance ... as well as the per-pixel masks ... These will allow the users to determine the validity and usefullness of each pixel in estimating the flux density recorded in that area of the sky"}.

$\bullet$ The DMSR (LSE-61), Section 1.2.11 "Level 1 Data Quality Report Definition" (ID: DMS-REQ-0097): \textit{"The DMS shall produce a Level 1 Data Quality Report that contains indicators of data quality that result from running the DMS pipelines, including at least ... detection efficiency for point sources vs. mag for each utilized filter."} However, this is a nightly data quality assessment and not a per-image product.

$\bullet$ The DMAD (LDM-151), Section 5.6.3 "MakeSelectionMaps", states that this calibration step \textit{"is responsible for producing multi-scale maps that describe LSST's depth and efficiency at detecting different classes of object. The details of what metrics will be mapped, the format and scale of the maps (e.g. hierarchical pixelizations vs. polygons), and the way the metrics will be computed are all unknown"}. It also states that this must be extendable to Level 3, but that \textit{"the details of what DM will provide still needs to be clarified to the community"}, and notes that the reprocessing time for fake plants could be prohibitive. (Section 3 "Alert Production" also specifies that in LDM-151 \textit{"we do not address estimation of the selection function for alert generation through the injection of simulated sources ... Source detection thresholds can be estimated through the use of sky sources"}.)

$\bullet$ Suchyta et al. (2016) presents \texttt{balrog}, a fake-embedding software package for detection efficiencies, and applies it in demonstration to DES data (it's not just for point sources, but uses \texttt{galsim} to embed shapes built of e.g., Sersic profiles).

$\bullet$ In a UW DM Brown Bag lunch meeting, it became clear that while there are many opinions on how to plant fake sources, not only are there no actual plans to do this, but there is no funding or FTQs allotted to figure out how the deliverable of detection efficiencies should be achieved.

$\bullet$ However, K.-T. revealed that a computational budget of 40\% has been allocated for fake insertion, with the understanding that this would happen in the daytime (i.e., not within 60 seconds). However, there has been a failure to schedule this into the development plan and there are no milestones for this project, and no person assigned to this task.

{\bf JIRA ticket DM-12584 is currently open to resolve whether or not the implantation of fake sources will be done as part of the Level 1 detection efficiency characterization, or if an alternate method will be sufficient for the science needs.}
